{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28c2599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 0. Setup ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import SAGEConv, to_hetero_with_bases\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7203323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows 11\\AppData\\Local\\Temp\\ipykernel_27344\\2958379719.py:22: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews = pd.concat([pd.read_csv(f) for f in review_files], ignore_index=True)\n",
      "C:\\Users\\Windows 11\\AppData\\Local\\Temp\\ipykernel_27344\\2958379719.py:22: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews = pd.concat([pd.read_csv(f) for f in review_files], ignore_index=True)\n",
      "C:\\Users\\Windows 11\\AppData\\Local\\Temp\\ipykernel_27344\\2958379719.py:22: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews = pd.concat([pd.read_csv(f) for f in review_files], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === 1. Load and Clean Data ===\n",
    "products = pd.read_csv(\"sephora_data/product_info.csv\")\n",
    "products = products.rename(columns={'product_id': 'itemID'})\n",
    "\n",
    "review_files = [\n",
    "    \"sephora_data/reviews_0-250.csv\",\n",
    "    \"sephora_data/reviews_250-500.csv\",\n",
    "    \"sephora_data/reviews_500-750.csv\",\n",
    "    \"sephora_data/reviews_750-1250.csv\",\n",
    "    \"sephora_data/reviews_1250-end.csv\"\n",
    "]\n",
    "reviews = pd.concat([pd.read_csv(f) for f in review_files], ignore_index=True)\n",
    "reviews = reviews.rename(columns={'author_id': 'userID', 'product_id': 'itemID', 'rating': 'rating'})\n",
    "reviews = reviews.dropna(subset=['userID', 'itemID', 'rating'])\n",
    "reviews = reviews.sample(n=10000, random_state=42)\n",
    "reviews['userID'] = reviews['userID'].astype(str)\n",
    "reviews['itemID'] = reviews['itemID'].astype(str)\n",
    "reviews['rating'] = reviews['rating'].astype(float)\n",
    "\n",
    "valid_item_ids = set(products['itemID'])\n",
    "interactions = reviews[reviews['itemID'].isin(valid_item_ids)]\n",
    "products = products[products['itemID'].isin(interactions['itemID'].unique())]\n",
    "\n",
    "user_id_map = {uid: i for i, uid in enumerate(interactions['userID'].unique())}\n",
    "item_id_map = {iid: i for i, iid in enumerate(interactions['itemID'].unique())}\n",
    "interactions['user_idx'] = interactions['userID'].map(user_id_map)\n",
    "interactions['item_idx'] = interactions['itemID'].map(item_id_map)\n",
    "\n",
    "train_data, test_data = train_test_split(interactions, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85d332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows 11\\AppData\\Local\\Temp\\ipykernel_27344\\650922330.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  edge_index = torch.tensor([\n"
     ]
    }
   ],
   "source": [
    "# === 2. Build Graph ===\n",
    "edge_index = torch.tensor([\n",
    "    interactions['user_idx'].values,\n",
    "    interactions['item_idx'].values\n",
    "], dtype=torch.long)\n",
    "\n",
    "data = HeteroData()\n",
    "data['user'].num_nodes = len(user_id_map)\n",
    "data['item'].num_nodes = len(item_id_map)\n",
    "data['user'].x = torch.zeros((len(user_id_map), 32))\n",
    "data['user', 'rates', 'item'].edge_index = edge_index\n",
    "data['item', 'rev_rates', 'user'].edge_index = edge_index[[1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f280f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. TF-IDF for item features ===\n",
    "products['content'] = (\n",
    "    products['product_name'].fillna('') + ' ' +\n",
    "    products['brand_name'].fillna('') + ' ' +\n",
    "    products['primary_category'].fillna('') + ' ' +\n",
    "    products['secondary_category'].fillna('') + ' ' +\n",
    "    products['highlights'].fillna('')\n",
    ")\n",
    "tfidf = TfidfVectorizer(max_features=100)\n",
    "tfidf_matrix = tfidf.fit_transform(products['content'].astype(str)).toarray()\n",
    "product_id_to_idx = {pid: i for i, pid in enumerate(products['itemID'])}\n",
    "item_features = np.zeros((len(item_id_map), tfidf_matrix.shape[1]))\n",
    "for item_id, graph_idx in item_id_map.items():\n",
    "    if item_id in product_id_to_idx:\n",
    "        item_features[graph_idx] = tfidf_matrix[product_id_to_idx[item_id]]\n",
    "data['item'].x = torch.tensor(item_features, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83365398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. GNN Model Definition ===\n",
    "class ManualGNN(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.user_conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.item_conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.user_conv2 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.item_conv2 = SAGEConv((-1, -1), hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_item = self.item_conv1((x_dict['user'], x_dict['item']), edge_index_dict[('user', 'rates', 'item')])\n",
    "        x_user = self.user_conv1((x_dict['item'], x_dict['user']), edge_index_dict[('item', 'rev_rates', 'user')])\n",
    "        x_item = F.relu(x_item)\n",
    "        x_user = F.relu(x_user)\n",
    "        x_item = self.item_conv2((x_user, x_item), edge_index_dict[('user', 'rates', 'item')])\n",
    "        x_user = self.user_conv2((x_item, x_user), edge_index_dict[('item', 'rev_rates', 'user')])\n",
    "        return {'user': x_user, 'item': x_item}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f1ce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 20.0668\n",
      "Epoch 02 | Loss: 11.7893\n",
      "Epoch 03 | Loss: 1.6386\n",
      "Epoch 04 | Loss: 41.1199\n",
      "Epoch 05 | Loss: 1.7753\n",
      "Epoch 06 | Loss: 5.9216\n",
      "Epoch 07 | Loss: 10.9932\n",
      "Epoch 08 | Loss: 13.3428\n",
      "Epoch 09 | Loss: 14.1884\n",
      "Epoch 10 | Loss: 14.3221\n",
      "Epoch 11 | Loss: 14.0810\n",
      "Epoch 12 | Loss: 13.5801\n",
      "Epoch 13 | Loss: 12.8359\n",
      "Epoch 14 | Loss: 11.8170\n",
      "Epoch 15 | Loss: 10.4714\n",
      "Epoch 16 | Loss: 8.7492\n",
      "Epoch 17 | Loss: 6.6460\n",
      "Epoch 18 | Loss: 4.3022\n",
      "Epoch 19 | Loss: 2.2067\n",
      "Epoch 20 | Loss: 1.4297\n"
     ]
    }
   ],
   "source": [
    "# === 5. Training Loop ===\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "model = ManualGNN(hidden_channels=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "user_indices = torch.tensor(train_data['user_idx'].values, dtype=torch.long, device=device)\n",
    "item_indices = torch.tensor(train_data['item_idx'].values, dtype=torch.long, device=device)\n",
    "ratings = torch.tensor(train_data['rating'].values, dtype=torch.float, device=device)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, 21):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    user_vecs = out['user'][user_indices]\n",
    "    item_vecs = out['item'][item_indices]\n",
    "    preds = (user_vecs * item_vecs).sum(dim=1)\n",
    "    loss = F.mse_loss(preds, ratings)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "782f3040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 3.0241\n"
     ]
    }
   ],
   "source": [
    "# === 6. Model Evaluation ===\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    user_test = torch.tensor(test_data['user_idx'].values, dtype=torch.long, device=device)\n",
    "    item_test = torch.tensor(test_data['item_idx'].values, dtype=torch.long, device=device)\n",
    "    ratings_test = torch.tensor(test_data['rating'].values, dtype=torch.float, device=device)\n",
    "\n",
    "    user_vecs = out['user'][user_test]\n",
    "    item_vecs = out['item'][item_test]\n",
    "    preds = (user_vecs * item_vecs).sum(dim=1)\n",
    "\n",
    "    test_loss = F.mse_loss(preds, ratings_test)\n",
    "    print(f\"Test MSE: {test_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2ac8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended itemIDs for user 7634976581 : ['P450614', 'P482529', 'P503191', 'P442539', 'P448937']\n"
     ]
    }
   ],
   "source": [
    "# === 7. Testing for one user ===\n",
    "user_id = list(user_id_map.keys())[0]  # pick first user\n",
    "user_idx = user_id_map[user_id]\n",
    "user_vec = out['user'][user_idx]\n",
    "\n",
    "scores = torch.matmul(out['item'], user_vec)\n",
    "topk = torch.topk(scores, k=5)\n",
    "\n",
    "recommended_item_indices = topk.indices.cpu().numpy()\n",
    "reverse_item_map = {v: k for k, v in item_id_map.items()}\n",
    "recommended_item_ids = [reverse_item_map[i] for i in recommended_item_indices]\n",
    "\n",
    "print(\"Top 5 recommended itemIDs for user\", user_id, \":\", recommended_item_ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GNN)",
   "language": "python",
   "name": "gnn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
