{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28c2599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 0. Setup ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import SAGEConv, to_hetero_with_bases\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7203323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows 11\\AppData\\Local\\Temp\\ipykernel_27344\\2958379719.py:22: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews = pd.concat([pd.read_csv(f) for f in review_files], ignore_index=True)\n",
      "C:\\Users\\Windows 11\\AppData\\Local\\Temp\\ipykernel_27344\\2958379719.py:22: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews = pd.concat([pd.read_csv(f) for f in review_files], ignore_index=True)\n",
      "C:\\Users\\Windows 11\\AppData\\Local\\Temp\\ipykernel_27344\\2958379719.py:22: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reviews = pd.concat([pd.read_csv(f) for f in review_files], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === 1. Load and Clean Data ===\n",
    "products = pd.read_csv(\"sephora_data/product_info.csv\")\n",
    "products = products.rename(columns={'product_id': 'itemID'})\n",
    "\n",
    "review_files = [\n",
    "    \"sephora_data/reviews_0-250.csv\",\n",
    "    \"sephora_data/reviews_250-500.csv\",\n",
    "    \"sephora_data/reviews_500-750.csv\",\n",
    "    \"sephora_data/reviews_750-1250.csv\",\n",
    "    \"sephora_data/reviews_1250-end.csv\"\n",
    "]\n",
    "reviews = pd.concat([pd.read_csv(f) for f in review_files], ignore_index=True)\n",
    "reviews = reviews.rename(columns={'author_id': 'userID', 'product_id': 'itemID', 'rating': 'rating'})\n",
    "reviews = reviews.dropna(subset=['userID', 'itemID', 'rating'])\n",
    "reviews = reviews.sample(n=10000, random_state=42)\n",
    "reviews['userID'] = reviews['userID'].astype(str)\n",
    "reviews['itemID'] = reviews['itemID'].astype(str)\n",
    "reviews['rating'] = reviews['rating'].astype(float)\n",
    "\n",
    "valid_item_ids = set(products['itemID'])\n",
    "interactions = reviews[reviews['itemID'].isin(valid_item_ids)]\n",
    "products = products[products['itemID'].isin(interactions['itemID'].unique())]\n",
    "\n",
    "user_id_map = {uid: i for i, uid in enumerate(interactions['userID'].unique())}\n",
    "item_id_map = {iid: i for i, iid in enumerate(interactions['itemID'].unique())}\n",
    "interactions['user_idx'] = interactions['userID'].map(user_id_map)\n",
    "interactions['item_idx'] = interactions['itemID'].map(item_id_map)\n",
    "\n",
    "train_data, test_data = train_test_split(interactions, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85d332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows 11\\AppData\\Local\\Temp\\ipykernel_27344\\650922330.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  edge_index = torch.tensor([\n"
     ]
    }
   ],
   "source": [
    "# === 2. Build Graph ===\n",
    "edge_index = torch.tensor([\n",
    "    interactions['user_idx'].values,\n",
    "    interactions['item_idx'].values\n",
    "], dtype=torch.long)\n",
    "\n",
    "data = HeteroData()\n",
    "data['user'].num_nodes = len(user_id_map)\n",
    "data['item'].num_nodes = len(item_id_map)\n",
    "data['user'].x = torch.zeros((len(user_id_map), 32))\n",
    "data['user', 'rates', 'item'].edge_index = edge_index\n",
    "data['item', 'rev_rates', 'user'].edge_index = edge_index[[1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f280f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. TF-IDF for item features ===\n",
    "products['content'] = (\n",
    "    products['product_name'].fillna('') + ' ' +\n",
    "    products['brand_name'].fillna('') + ' ' +\n",
    "    products['primary_category'].fillna('') + ' ' +\n",
    "    products['secondary_category'].fillna('') + ' ' +\n",
    "    products['highlights'].fillna('')\n",
    ")\n",
    "tfidf = TfidfVectorizer(max_features=100)\n",
    "tfidf_matrix = tfidf.fit_transform(products['content'].astype(str)).toarray()\n",
    "product_id_to_idx = {pid: i for i, pid in enumerate(products['itemID'])}\n",
    "item_features = np.zeros((len(item_id_map), tfidf_matrix.shape[1]))\n",
    "for item_id, graph_idx in item_id_map.items():\n",
    "    if item_id in product_id_to_idx:\n",
    "        item_features[graph_idx] = tfidf_matrix[product_id_to_idx[item_id]]\n",
    "data['item'].x = torch.tensor(item_features, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83365398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. GNN Model Definition ===\n",
    "class ManualGNN(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.user_conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.item_conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.user_conv2 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.item_conv2 = SAGEConv((-1, -1), hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_item = self.item_conv1((x_dict['user'], x_dict['item']), edge_index_dict[('user', 'rates', 'item')])\n",
    "        x_user = self.user_conv1((x_dict['item'], x_dict['user']), edge_index_dict[('item', 'rev_rates', 'user')])\n",
    "        x_item = F.relu(x_item)\n",
    "        x_user = F.relu(x_user)\n",
    "        x_item = self.item_conv2((x_user, x_item), edge_index_dict[('user', 'rates', 'item')])\n",
    "        x_user = self.user_conv2((x_item, x_user), edge_index_dict[('item', 'rev_rates', 'user')])\n",
    "        return {'user': x_user, 'item': x_item}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f1ce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 20.0668\n",
      "Epoch 02 | Loss: 11.7893\n",
      "Epoch 03 | Loss: 1.6386\n",
      "Epoch 04 | Loss: 41.1199\n",
      "Epoch 05 | Loss: 1.7753\n",
      "Epoch 06 | Loss: 5.9216\n",
      "Epoch 07 | Loss: 10.9932\n",
      "Epoch 08 | Loss: 13.3428\n",
      "Epoch 09 | Loss: 14.1884\n",
      "Epoch 10 | Loss: 14.3221\n",
      "Epoch 11 | Loss: 14.0810\n",
      "Epoch 12 | Loss: 13.5801\n",
      "Epoch 13 | Loss: 12.8359\n",
      "Epoch 14 | Loss: 11.8170\n",
      "Epoch 15 | Loss: 10.4714\n",
      "Epoch 16 | Loss: 8.7492\n",
      "Epoch 17 | Loss: 6.6460\n",
      "Epoch 18 | Loss: 4.3022\n",
      "Epoch 19 | Loss: 2.2067\n",
      "Epoch 20 | Loss: 1.4297\n"
     ]
    }
   ],
   "source": [
    "# === 5. Training Loop ===\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "model = ManualGNN(hidden_channels=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "user_indices = torch.tensor(train_data['user_idx'].values, dtype=torch.long, device=device)\n",
    "item_indices = torch.tensor(train_data['item_idx'].values, dtype=torch.long, device=device)\n",
    "ratings = torch.tensor(train_data['rating'].values, dtype=torch.float, device=device)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, 21):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    user_vecs = out['user'][user_indices]\n",
    "    item_vecs = out['item'][item_indices]\n",
    "    preds = (user_vecs * item_vecs).sum(dim=1)\n",
    "    loss = F.mse_loss(preds, ratings)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e78c56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression Metrics:\n",
      "MAE: 1.2541\n",
      "RMSE: 1.7390\n",
      "MSE: 3.0241\n",
      "\n",
      "Classification Metrics (Threshold = 4.0):\n",
      "Accuracy: 0.8190\n",
      "Precision: 0.8190\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9005\n"
     ]
    }
   ],
   "source": [
    "# === 6. Model Evaluation with Metrics ===\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    \n",
    "    # Test set\n",
    "    user_test = torch.tensor(test_data['user_idx'].values, dtype=torch.long, device=device)\n",
    "    item_test = torch.tensor(test_data['item_idx'].values, dtype=torch.long, device=device)\n",
    "    ratings_test = torch.tensor(test_data['rating'].values, dtype=torch.float, device=device)\n",
    "\n",
    "    # Get latent vectors\n",
    "    user_vecs = out['user'][user_test]\n",
    "    item_vecs = out['item'][item_test]\n",
    "    preds = (user_vecs * item_vecs).sum(dim=1)\n",
    "\n",
    "    # === Regression Metrics ===\n",
    "    preds_np = preds.cpu().numpy()\n",
    "    ratings_np = ratings_test.cpu().numpy()\n",
    "\n",
    "    mse = mean_squared_error(ratings_np, preds_np)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(ratings_np, preds_np)\n",
    "\n",
    "    print(f\"\\nRegression Metrics:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "\n",
    "    # === Classification Metrics ===\n",
    "    # Define binary threshold (e.g. rating >= 4 is positive)\n",
    "    threshold = 4.0\n",
    "    binary_true = (ratings_np >= threshold).astype(int)\n",
    "    binary_pred = (preds_np >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(binary_true, binary_pred)\n",
    "    precision = precision_score(binary_true, binary_pred, zero_division=0)\n",
    "    recall = recall_score(binary_true, binary_pred, zero_division=0)\n",
    "    f1 = f1_score(binary_true, binary_pred, zero_division=0)\n",
    "\n",
    "    print(f\"\\nClassification Metrics (Threshold = {threshold}):\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a23a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretation:\n",
    "\n",
    "#MAE < 1.5 is acceptable in many recommender systems, but could be improved.\n",
    "#RMSE being higher than MAE indicates some big errors exist (outliers or poorly predicted users/items).\n",
    "#Aiming to lower both via better GNNs or hyperparameter tuning.\n",
    "\n",
    "\n",
    "#Recall = 1.0: The model is very cautious — it predicts nearly everything positive, so it doesn't miss any true likes.\n",
    "#Precision = 0.819: Still quite good — though ~18% of your positive recommendations may be irrelevant.\n",
    "#F1 = 0.9005: Strong balance between identifying all good items (recall) and being right when you say something is good (precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f3040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 3.0241\n"
     ]
    }
   ],
   "source": [
    "# === 6.1 Just the MSE (Can be ignored for later) ===\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    user_test = torch.tensor(test_data['user_idx'].values, dtype=torch.long, device=device)\n",
    "    item_test = torch.tensor(test_data['item_idx'].values, dtype=torch.long, device=device)\n",
    "    ratings_test = torch.tensor(test_data['rating'].values, dtype=torch.float, device=device)\n",
    "\n",
    "    user_vecs = out['user'][user_test]\n",
    "    item_vecs = out['item'][item_test]\n",
    "    preds = (user_vecs * item_vecs).sum(dim=1)\n",
    "\n",
    "    test_loss = F.mse_loss(preds, ratings_test)\n",
    "    print(f\"Test MSE: {test_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2ac8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended itemIDs for user 7634976581 : ['P450614', 'P482529', 'P503191', 'P442539', 'P448937']\n"
     ]
    }
   ],
   "source": [
    "# === 7. Testing for one user ===\n",
    "user_id = list(user_id_map.keys())[0]  # pick first user\n",
    "user_idx = user_id_map[user_id]\n",
    "user_vec = out['user'][user_idx]\n",
    "\n",
    "scores = torch.matmul(out['item'], user_vec)\n",
    "topk = torch.topk(scores, k=5)\n",
    "\n",
    "recommended_item_indices = topk.indices.cpu().numpy()\n",
    "reverse_item_map = {v: k for k, v in item_id_map.items()}\n",
    "recommended_item_ids = [reverse_item_map[i] for i in recommended_item_indices]\n",
    "\n",
    "print(\"Top 5 recommended itemIDs for user\", user_id, \":\", recommended_item_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9910592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8. GAT Model Definition ===\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GATRecommender(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.user_conv1 = GATConv((-1, -1), hidden_channels, heads=2, concat=False)\n",
    "        self.item_conv1 = GATConv((-1, -1), hidden_channels, heads=2, concat=False)\n",
    "        self.user_conv2 = GATConv((-1, -1), hidden_channels, heads=2, concat=False)\n",
    "        self.item_conv2 = GATConv((-1, -1), hidden_channels, heads=2, concat=False)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_item = self.item_conv1((x_dict['user'], x_dict['item']), edge_index_dict[('user', 'rates', 'item')])\n",
    "        x_item = F.relu(x_item)\n",
    "\n",
    "        x_user = self.user_conv1((x_dict['item'], x_dict['user']), edge_index_dict[('item', 'rev_rates', 'user')])\n",
    "        x_user = F.relu(x_user)\n",
    "\n",
    "        x_item = self.item_conv2((x_user, x_item), edge_index_dict[('user', 'rates', 'item')])\n",
    "        x_item = F.relu(x_item)\n",
    "        x_user = self.user_conv2((x_item, x_user), edge_index_dict[('item', 'rev_rates', 'user')])\n",
    "        x_user = F.relu(x_user)\n",
    "\n",
    "        return {'user': x_user, 'item': x_item}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "679402b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GAT] Epoch 01 | Loss: 19.6992\n",
      "[GAT] Epoch 02 | Loss: 19.4423\n",
      "[GAT] Epoch 03 | Loss: 18.7199\n",
      "[GAT] Epoch 04 | Loss: 16.9971\n",
      "[GAT] Epoch 05 | Loss: 13.5137\n",
      "[GAT] Epoch 06 | Loss: 7.8144\n",
      "[GAT] Epoch 07 | Loss: 2.2884\n",
      "[GAT] Epoch 08 | Loss: 11.2754\n",
      "[GAT] Epoch 09 | Loss: 5.4946\n",
      "[GAT] Epoch 10 | Loss: 2.0797\n",
      "[GAT] Epoch 11 | Loss: 2.8334\n",
      "[GAT] Epoch 12 | Loss: 4.4268\n",
      "[GAT] Epoch 13 | Loss: 5.4494\n",
      "[GAT] Epoch 14 | Loss: 5.6756\n",
      "[GAT] Epoch 15 | Loss: 5.1837\n",
      "[GAT] Epoch 16 | Loss: 4.1358\n",
      "[GAT] Epoch 17 | Loss: 2.8298\n",
      "[GAT] Epoch 18 | Loss: 1.8240\n",
      "[GAT] Epoch 19 | Loss: 1.8706\n",
      "[GAT] Epoch 20 | Loss: 2.9872\n"
     ]
    }
   ],
   "source": [
    "# === 9. Training GAT Model ===\n",
    "gat_model = GATRecommender(hidden_channels=64).to(device)\n",
    "optimizer = torch.optim.Adam(gat_model.parameters(), lr=0.005)\n",
    "\n",
    "gat_model.train()\n",
    "for epoch in range(1, 21):\n",
    "    optimizer.zero_grad()\n",
    "    out = gat_model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    user_vecs = out['user'][user_indices]\n",
    "    item_vecs = out['item'][item_indices]\n",
    "\n",
    "    preds = (user_vecs * item_vecs).sum(dim=1)\n",
    "    loss = F.mse_loss(preds, ratings)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"[GAT] Epoch {epoch:02d} | Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8088208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[GAT Evaluation]\n",
      "MAE: 1.4319, RMSE: 1.8891, MSE: 3.5688\n",
      "Accuracy: 0.7960, Precision: 0.8187, Recall: 0.9646, F1 Score: 0.8857\n"
     ]
    }
   ],
   "source": [
    "# === 10. Evaluate GAT Model ===\n",
    "gat_model.eval()\n",
    "with torch.no_grad():\n",
    "    out = gat_model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    user_test = torch.tensor(test_data['user_idx'].values, dtype=torch.long, device=device)\n",
    "    item_test = torch.tensor(test_data['item_idx'].values, dtype=torch.long, device=device)\n",
    "    ratings_test = torch.tensor(test_data['rating'].values, dtype=torch.float, device=device)\n",
    "\n",
    "    user_vecs = out['user'][user_test]\n",
    "    item_vecs = out['item'][item_test]\n",
    "    preds = (user_vecs * item_vecs).sum(dim=1)\n",
    "\n",
    "    preds_np = preds.cpu().numpy()\n",
    "    ratings_np = ratings_test.cpu().numpy()\n",
    "\n",
    "    from sklearn.metrics import (\n",
    "        mean_squared_error, mean_absolute_error,\n",
    "        accuracy_score, precision_score, recall_score, f1_score\n",
    "    )\n",
    "\n",
    "    mse = mean_squared_error(ratings_np, preds_np)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(ratings_np, preds_np)\n",
    "\n",
    "    binary_true = (ratings_np >= 4).astype(int)\n",
    "    binary_pred = (preds_np >= 4).astype(int)\n",
    "\n",
    "    acc = accuracy_score(binary_true, binary_pred)\n",
    "    precision = precision_score(binary_true, binary_pred, zero_division=0)\n",
    "    recall = recall_score(binary_true, binary_pred, zero_division=0)\n",
    "    f1 = f1_score(binary_true, binary_pred, zero_division=0)\n",
    "\n",
    "    print(f\"\\n[GAT Evaluation]\")\n",
    "    print(f\"MAE: {mae:.4f}, RMSE: {rmse:.4f}, MSE: {mse:.4f}\")\n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a676f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretations\n",
    "\n",
    "#MAE (1.4319)\n",
    "#Higher than GraphSAGE’s 1.2541 → on average, GAT makes slightly larger absolute errors.\n",
    "#Suggests GAT is less precise in rating prediction, possibly because it's more focused on ranking rather than exact scores.\n",
    "\n",
    "#RMSE (1.8891)\n",
    "#Also higher than GraphSAGE’s 1.7390 → GAT makes more severe individual errors (squared error is more sensitive to outliers).\n",
    "\n",
    "#But now the interesting part — Classification Metrics (Threshold ≥ 4)\n",
    "#Accuracy & F1 Score: Slightly lower than GraphSAGE but still strong.\n",
    "#Precision is almost identical (82%).\n",
    "#Recall dropped slightly from perfect 1.0 to 0.9646 — which is still excellent and suggests GAT still captures most \"liked\" items.\n",
    "\n",
    "#Conclusion for report:\n",
    "#1. GAT does not outperform GraphSAGE in numeric accuracy (MAE/RMSE):\n",
    "#GraphSAGE might be more stable in capturing exact rating values.\n",
    "#This suggests that attention didn’t help the model better estimate exact ratings, at least with the current setup.\n",
    "\n",
    "#2. GAT achieves nearly the same classification performance:\n",
    "#F1, precision, and recall are all strong, with slightly more conservative behavior than GraphSAGE (lower recall).\n",
    "#Suggests GAT is better at ranking top-N items based on general preference, even if predicted rating is off.\n",
    "\n",
    "#Final note: While GAT introduces attention and slightly changes the model behavior, it does not outperform GraphSAGE in numeric error metrics (MAE/RMSE). \n",
    "# However, its classification performance remains strong, indicating it's still a reliable model for distinguishing liked products. \n",
    "# These results suggest that GraphSAGE may be more suitable for rating prediction, while GAT can still be useful in ranking or top-k recommendation settings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65a67a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended itemIDs by GAT for user 7634976581 : ['P481347', 'P482320', 'P503191', 'P504644', 'P466155']\n"
     ]
    }
   ],
   "source": [
    "# === 11. GAT Top 5 Recommendations for a User ===\n",
    "user_vec = out['user'][user_idx]\n",
    "scores = torch.matmul(out['item'], user_vec)\n",
    "topk = torch.topk(scores, k=5)\n",
    "recommended_item_indices = topk.indices.cpu().numpy()\n",
    "recommended_item_ids = [reverse_item_map[i] for i in recommended_item_indices]\n",
    "\n",
    "print(\"Top 5 recommended itemIDs by GAT for user\", user_id, \":\", recommended_item_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GNN)",
   "language": "python",
   "name": "gnn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
